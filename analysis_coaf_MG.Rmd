---
title: "linefollow_analysis"
author: "Nils Wendel Heinrich"
date: "2024-07-17"
output: pdf_document
---

```{r global, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r setup, include=FALSE}

library(tidyverse)
library(lme4)
library(lmerTest)
library(sjPlot)
library(latex2exp)
library(ggplot2)
library(fitdistrplus)
library(simr)
library(arrow)
library(MASS)
library(MuMIn)

set.seed(36)
N_iterations <- 100

```


```{r data, echo=FALSE}

#load data 
#(Nils)
#trial_data <- read_csv("data/trialwise_data.csv")

#Maren
trial_data <- read.csv("H:/Maren/Experiments/COAF/Main/data/experiment_preprocessed/trialwise_data.csv")
questionnaire_data <- read.csv("H:/Maren/Experiments/COAF/Main/data/questionnaire_preprocessed/questionnaire_scores.csv")

# factorization
trial_data$feedback <- factor(trial_data$feedback, levels = c("neutral", "positive", "negative"))
trial_data$input_noise_magnitude <- factor(trial_data$input_noise_magnitude, levels = c("0.5", "2"))
trial_data$code <- factor(trial_data$code) #added as factor variable by Maren

#? also code input_noise_ascending as factor?
#trial_data$inpnoise_ascending <- factor(trial_data$inpnoise_ascending, levels = c("1", "2", "3", "4"))

```

Create one dataset containing both the experimental data and the questionnaire scores.
Furthermore, exclude participant 12 and 14 from all statistical analyses.
```{r create final dataset, echo=FALSE}

#exclude pp 12 and 14 from experimental data
trial_data <- trial_data %>% filter(code != 12 & code != 14)

#rename "ID" to "code"
colnames(questionnaire_data)[colnames(questionnaire_data) == "ID"] <- "code"
all_data <- merge(trial_data, questionnaire_data, by = "code", all.x = TRUE)

#add categorical depression variable with participants scorint >= 16 (critical) scoring 1 and participants scoring < 16 scoring 0
all_data$CESDR_cat <- ifelse(all_data$CESDR >= 16, 1, 0)
all_data$CESDR_cat <- as.factor(all_data$CESDR_cat )

```

# H1: Performance (line deviation) is higher for low-input noise spaceship than high-input noise spaceship
# Exploratory analysis 1: Did performance (line deviation) improve across blocks of trials 

Distributional analysis:
```{r avg_boxcox, echo=FALSE}

lambda_avg <- boxcox(lm(all_data$avg_dist_trialwise ~ 1))

lambda_avg$x[which(lambda_avg$y == max(lambda_avg$y))]

```

The expected value, lambda is close to 0, which implies a log transformation.

### null model
```{r null model, echo=FALSE}
dist_null <- lmer(log(avg_dist_trialwise) ~ 1 + (1|code), data = all_data)
summary(dist_null)
```

Model estimate back transformed
```{r null model, echo=FALSE}

exp(fixef(dist_null)[1])
exp(0.02502)

```

```{r h1_lm, echo=FALSE}

# full model
h1_lm <- lmer(log(avg_dist_trialwise) ~ input_noise_magnitude * inpnoise_ascending + (1|code), data = all_data)

summary(h1_lm)

```
Model estimate back transformed
```{r null model, echo=FALSE}
#intercept
exp(fixef(h1_lm)[1]) 
exp(2.633e-02)

#effect of input noise
exp(fixef(h1_lm)[2]) #increase in line distance when changing input noise from 0.5 to 2
exp(1.212e-02)

#effect of block number
exp(fixef(h1_lm)[3]) #decrease in line distance when advancing by one block
exp(3.130e-03)

#effect of input noise * block number interaction 
exp(fixef(h1_lm)[4]) 
exp(4.427e-03)

```

effect size of the models' effects
parametric bootstrap:
```{r h1_bootstrap, echo=FALSE}

#confint(h1_lm, nsim=N_iterations, parm=c('input_noise_magnitude2', 'inpnoise_ascending'), method='boot')

confint(h1_lm, nsim=N_iterations, method='boot')
```

# H2 - 5: Larger input noise decreases SoC Ratings, Positive Outcomes increase SoC Ratings, Effect of Feedback Valence is larger for high input noise blocks, Improved Performance Increases SoC Ratings
# Exploratory Analysis 2: Is the effect of negative or positive feedback on SoC stronger or do they have an equal influence on SoC ratings?

Distributional analysis:
```{r h1_boxcox, echo=FALSE}

lambda_soc <- boxcox(lm(all_data$SoC ~ 1))

lambda_soc$x[which(lambda_soc$y == max(lambda_soc$y))]

```
referring to:
https://www.statisticshowto.com/probability-and-statistics/normal-distributions/box-cox-transformation/

lambda, the expected value is closer to 0.5 than 1 (1 would be ideal, suggesting no transformation). 0.5 implies a âˆš transformation, which we will apply. 
"a boxcox distributional analysis implied a square root transformation of the predicted variable"


### null model 
predict mean (independent of any predictors) SoC rating
```{r h1_lm, echo=FALSE}

soc_null <- lmer(sqrt(SoC) ~ 1 + (1|code), data = all_data)
summary(soc_null)

```
How much variance in SoC Ratings is explained by "Code"?
```{r h1_lm, echo=FALSE}

fixef(soc_null)**2
0.02771**2

```

full model
```{r h2_lm, echo=FALSE}

# full model
h2_lm <- lmer(sqrt(SoC) ~ input_noise_magnitude * feedback * avg_dist_trialwise + (1|code), data = all_data)

summary(h2_lm)

```

Model estimate back transformed
```{r null model, echo=FALSE}
#intercept
fixef(h2_lm)[1]**2
(3.280e-02)**2

#contrast high (vs. low) input noise
fixef(h2_lm)[2]**2
(2.970e-02)**2

#contrast positive (vs. neutral) feedback
fixef(h2_lm)[3]**2
(2.699e-02)**2

#contrast negative (vs. neutral) feedback
fixef(h2_lm)[4]**2
(2.792e-02)**2

#.... => results are strange, not further reported from here

```
